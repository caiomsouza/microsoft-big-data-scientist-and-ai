# Analytics Roles and Responsabilities 

### Big Data Architect roles and responsibilites | Skills of a Big Data Architect

What is Big data?
 
The name itself suggests that it explains about the large data which are both structured and unstructured which can be used for data mining.
The Big data is huge and it is stored on a global level. This requires a set of technologies and technique to organize the data, store and analyze.  This data is very much useful for influencing business decisions through the collection of large set of data.

Big Data architect Roles and Responsibilities
 
This will be a senior level position and your duty to solve big data problems by structuring and analyze the behavior of data using a data technology called Hadoop.  Hadoop takes care of Debugging, Monitoring and performance tuning.  Big data architect must able to handle large scale database, analyzing the patterns of data to make strong and accurate business decisions.  Big data architect must be a strong team leader, ability to mentor and collaborate with the other teams. Ability to build rapport and relationship with the vendors and partner companies.

Skills of a big data architect
 
* Strong decision making skills in terms of data analysis and must have the ability to architect large data.
* Machine learning is something which is a very important skill to know to do this job. Knowing about the pattern recognition, text mining, clustering is an advantage to handle big data.
* Strong experience in programming languages and latest technologies such as :  C#.NET, Elastic, all types of Javascript frameworks, HTML5, CSS, RESTful Services,  Spark, Python, Linux, Hive, Kafka, Redis Cloudera etc.
* Need knowledge and experience with the latest data technologies  and frameworks  such as Hadoop, MapReduce, Pig, Hive, HBase, Oozie, Flume, ZooKeeper, MongoDB, NoSQL and Cassandra.
* Many companies look out for people with knowledge of cloud computing and who has got the experience working with various cloud environments.
* Agile and scrum methodologies is a must to know for this job.
* Experience with Data warehousing and data mining is a must.

Preferred skills of a Big Data Architect by many employers
 
Big data architect must have great experience and knowledge about data architectures and could able to handle and analyze large data.
Hadoop is something is a preferred skill/ experience that many employers expect with the Big data architect.
Python, Java , C# and .Net are the programming technologies that are preferred by many companies.
MongoDB, NoSQL, Oracle and Cassandra are some of the database experience that employers look in for a Big Data architect.
 
As per statistics, USA requires more big data architects and there are going to be more jobs opened in the future, those who are good and have got experience with data architecture can easily take up Big Data as a career.

Source:
https://www.jobawareness.com/bigdata-architect-responsibilities-skills.asp

These are the main tasks which Architect need to do or should have these skill set to become Big Data Architect.

* Should be able to Design, Architect, and help Maintain Enterprise solutions on the big data analytics platform
* Should be able to lead systems implementations and detailed functional/technical system design
* Leverage extensive knowledge of distributed systems, process flows and procedures to aid analyses and recommendations for solution offerings
* Guide/Mentor/Assist in development of the proposed architectural solution
* Develop automation for the setup and maintenance of the Big Data Platform
* Lead performance tuning activities of the system
* Lead the team in infrastructure setup phases
* Design, Architect, and help Maintain Enterprise solutions on the big data analytics platform
* Lead systems implementations and detailed functional/technical system design
* Need to take end-to-end ownership for solution components and bring in design best practices and tools

Source:
http://www.hadoopadmin.co.in/bigdata-architect/role-and-responsibilities/

Big Data Hadoop architects have evolved to become vital links between businesses and technology. They’re responsible for planning and designing next-generation big-data systems and managing large-scale development and deployment of Hadoop applications. Hadoop architects are among the highest paid professionals in the IT industry, earning on average between $91,392 and $133,988 per year, and as much as $200,000 per year. <BR>

Big Data Architect - Manage the complete lifecycle of a Hadoop solution:
* including requirement analysis
* platform selection
* design of technical architecture
* design of application design and development
* testing
* deployment of the proposed solution.

Source: <BR>
https://www.simplilearn.com/how-to-become-a-big-data-hadoop-architect-article <BR>
 
 
Forrester Analyst Mike Gualtieri recently predicted that "100 percent of large companies" would adopt Hadoop over the next couple of years. <BR>
 
A report from Market Research forecasts that the Hadoop market will grow at a compound annual growth rate (CAGR) of 58 percent through 2022 and that it will be worth more than $1 billion by 2020. IBM, too, believes so strongly in open source Big Data tools that it assigned 3,500 researchers to work on Apache Spark, a tool that is part of the Hadoop ecosystem. 

Source: <BR>
https://www.simplilearn.com/how-to-become-a-big-data-hadoop-architect-article <BR>


Organizations that look to leverage big data are qualitatively different from those that don’t. That’s because: 1) they simply have much have more data to deal with — typically petabytes, not terabytes, 2) that data comes from many different sources in many different formats, and 3) all that data serves one or possibly two core strategies. One strategy is to generate critical insights at near real-time speed. The other is to automate massively scaled operations in real time (think Netflix videos or GE’s remote predictive maintenance on its customers’ jet and locomotive engines). In both strategies, big data enables a business model differentiated by speed, scale, agility, and intelligence.

Deep skills in big data tools and technologies (like those listed in most big data architect job postings). Those include data warehouse technologies like Accumulo, Hadoop, Panoply, Redshift architecture, MapReduce, Hive, HBase, MongoDB, and Cassandra as well as data modeling and mining tools like Impala, Oozie, Mahout, Flume, ZooKeeper, and Sqoop. Relevant programming languages include Java, Linux, PHP, and Python. BI and visualization tools include Apache Zeppelin, Chartio, R Studio, and Tableau. A big data architect should obviously also be experienced designing and implementing large on-prem and cloud-based data warehouse solutions utilizing cluster and parallel RDMS and NoSQL architectures.

Source: <BR>
https://blog.panoply.io/big-data-architect-role <BR>
 
3 Ways to Build An ETL Process <BR>
https://panoply.io/data-warehouse-guide/3-ways-to-build-an-etl-process/ <BR>

Extract, transform, and load (ETL) <BR>
https://docs.microsoft.com/en-us/azure/architecture/data-guide/relational-data/etl <BR>
